{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1BFToyeKW5-2Tpk4ZtXqmrgcg1XgG8CnR",
      "authorship_tag": "ABX9TyPXSdq+CbO7/2S/gACtAfXb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yezzzzin/object-detectinon/blob/main/AiProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 라이브러리 import"
      ],
      "metadata": {
        "id": "dY2USDyzdIjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NInloefiC7ra",
        "outputId": "8a429739-e320-4e66-a990-a109e669a0db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "I5eOvh2KdBZB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "zJmrmu21CAlS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 데이터 로드 & 전처리"
      ],
      "metadata": {
        "id": "4hP2ul8NzYfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 및 분할\n",
        "data = pd.read_csv('/content/drive/MyDrive/dataset.csv')\n",
        "\n",
        "train_data = pd.DataFrame()\n",
        "test_data = pd.DataFrame()\n",
        "\n",
        "for label in data['라벨'].unique():\n",
        "    label_data = data[data['라벨'] == label]\n",
        "    train_label_data, test_label_data = train_test_split(label_data, test_size=200, random_state=42)  # Splitting\n",
        "    train_data = train_data.append(train_label_data)\n",
        "    test_data = test_data.append(test_label_data)\n",
        "\n",
        "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
        "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(train_data[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAy8ZnrcdN1J",
        "outputId": "4bedb8b0-5596-45d5-d280-9af0877f7a0b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               데이터위치        라벨\n",
            "0  /content/drive/MyDrive/img/squirrel/squirrel.6...  squirrel\n",
            "1      /content/drive/MyDrive/img/lamb/lamb.955.jpeg      lamb\n",
            "2  /content/drive/MyDrive/img/elephant/elephant.6...  elephant\n",
            "3      /content/drive/MyDrive/img/lamb/lamb.630.jpeg      lamb\n",
            "4        /content/drive/MyDrive/img/lamb/lamb.22.jpg      lamb\n",
            "5  /content/drive/MyDrive/img/elephant/elephant.3...  elephant\n",
            "6    /content/drive/MyDrive/img/horse/horse.563.jpeg     horse\n",
            "7    /content/drive/MyDrive/img/horse/horse.344.jpeg     horse\n",
            "8  /content/drive/MyDrive/img/elephant/elephant.3...  elephant\n",
            "9  /content/drive/MyDrive/img/squirrel/squirrel.1...  squirrel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-408b67e455ef>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(train_label_data)\n",
            "<ipython-input-12-408b67e455ef>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  test_data = test_data.append(test_label_data)\n",
            "<ipython-input-12-408b67e455ef>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(train_label_data)\n",
            "<ipython-input-12-408b67e455ef>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  test_data = test_data.append(test_label_data)\n",
            "<ipython-input-12-408b67e455ef>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(train_label_data)\n",
            "<ipython-input-12-408b67e455ef>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  test_data = test_data.append(test_label_data)\n",
            "<ipython-input-12-408b67e455ef>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(train_label_data)\n",
            "<ipython-input-12-408b67e455ef>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  test_data = test_data.append(test_label_data)\n",
            "<ipython-input-12-408b67e455ef>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(train_label_data)\n",
            "<ipython-input-12-408b67e455ef>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  test_data = test_data.append(test_label_data)\n",
            "<ipython-input-12-408b67e455ef>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(train_label_data)\n",
            "<ipython-input-12-408b67e455ef>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  test_data = test_data.append(test_label_data)\n",
            "<ipython-input-12-408b67e455ef>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_data.append(train_label_data)\n",
            "<ipython-input-12-408b67e455ef>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  test_data = test_data.append(test_label_data)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 정의 데이터셋 클래스\n",
        "class AnimalDataset(Dataset):\n",
        "    def __init__(self, dataframe, label_map, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.label_map = label_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.dataframe.iloc[idx, 0]\n",
        "        image = Image.open(image_path).convert(\"RGB\")  # tensor 단위 오류 해결 위해 명시\n",
        "        label_name = self.dataframe.iloc[idx, 1]\n",
        "        label = self.label_map[label_name]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# 라벨을 정수로 매핑 - 추후 label을 숫자가 아닌 글자로 반환하도록 해주는 딕셔너리\n",
        "label_map = {'cat': 0, 'cow': 1, 'dog': 2, 'elephant': 3, 'horse': 4, 'lamb': 5, 'squirrel': 6}\n",
        "\n",
        "# 이미지 전처리를 위한 transform 함수 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 데이터셋 및 데이터 로더 생성\n",
        "train_dataset = AnimalDataset(train_data, label_map, transform=transform)  # 인스턴스는 init 파라미터 따름\n",
        "test_dataset = AnimalDataset(test_data, label_map, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "TiPZRXY7dSvr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 훈련"
      ],
      "metadata": {
        "id": "4AfUGweezr4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)  # imageNet 데이터로 훈련된 모델 불러옴\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 7)  # 7종의 동물 클래스\n",
        "model = model.to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습 함수\n",
        "def train_model(model, criterion, optimizer, num_epochs=20):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        # 진행률 표시를 위해 tqdm을 사용\n",
        "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # 데이터를 GPU로 이동\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        tqdm.write(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "VhIeKtNidXkV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "trained_model = train_model(model, criterion, optimizer, num_epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EdoIibIz-mb",
        "outputId": "5a6d119f-b21a-4884-d4be-5f714500333b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|██████████| 700/700 [00:58<00:00, 11.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.0511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|██████████| 700/700 [00:58<00:00, 11.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20, Loss: 0.0203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|██████████| 700/700 [00:58<00:00, 12.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20, Loss: 0.0129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|██████████| 700/700 [00:59<00:00, 11.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20, Loss: 0.0105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|██████████| 700/700 [00:58<00:00, 12.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20, Loss: 0.0075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|██████████| 700/700 [01:00<00:00, 11.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20, Loss: 0.0064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|██████████| 700/700 [00:57<00:00, 12.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20, Loss: 0.0075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|██████████| 700/700 [00:58<00:00, 11.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20, Loss: 0.0071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|██████████| 700/700 [00:57<00:00, 12.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20, Loss: 0.0063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|██████████| 700/700 [01:01<00:00, 11.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20, Loss: 0.0065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|██████████| 700/700 [00:58<00:00, 11.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20, Loss: 0.0038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|██████████| 700/700 [00:58<00:00, 11.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20, Loss: 0.0045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|██████████| 700/700 [00:59<00:00, 11.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20, Loss: 0.0037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|██████████| 700/700 [00:58<00:00, 12.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20, Loss: 0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|██████████| 700/700 [00:58<00:00, 11.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20, Loss: 0.0036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|██████████| 700/700 [00:58<00:00, 11.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20, Loss: 0.0038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|██████████| 700/700 [01:00<00:00, 11.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20, Loss: 0.0042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|██████████| 700/700 [00:59<00:00, 11.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20, Loss: 0.0049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|██████████| 700/700 [00:59<00:00, 11.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20, Loss: 0.0033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|██████████| 700/700 [01:01<00:00, 11.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20, Loss: 0.0026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 함수\n",
        "def test_model_accuracy(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)  # 모델을 적절한 디바이스로 이동\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # 데이터를 GPU로 이동\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'테스트 데이터에 대한 모델 정확도: {accuracy:.2f}%')\n",
        "\n",
        "def test_model_f1_confusion_matrix(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():  # 그래디언트 계산을 비활성화\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "    # 혼동 행렬 계산\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # F1 Score 계산\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "ElkVPX7leDbD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model_accuracy(trained_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzJpWGVvzpu2",
        "outputId": "6d4b82b6-9406-4bbb-9b8a-6bab6708cd98"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터에 대한 모델 정확도: 94.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model_f1_confusion_matrix(trained_model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R-RfJFm0DLh",
        "outputId": "7341417e-69d4-438c-f8b1-a0fb70b1df71"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[193   0   5   0   0   1   1]\n",
            " [  0 186   2   2   3   5   2]\n",
            " [  6   1 190   0   2   0   1]\n",
            " [  0   5   0 192   0   2   1]\n",
            " [  0  15   1   3 176   3   2]\n",
            " [  1   3   3   1   2 189   1]\n",
            " [  4   0   1   1   0   1 193]]\n",
            "F1 Score: 0.9421\n"
          ]
        }
      ]
    }
  ]
}